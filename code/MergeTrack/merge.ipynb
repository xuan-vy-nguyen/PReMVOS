{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting up\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print(\"Starting up\")\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from copy import deepcopy as copy\n",
    "from scipy.misc import imread\n",
    "import sys\n",
    "import ipdb\n",
    "from merge_common import *\n",
    "sys.path.append(\"/home/hthieu/UTUBEVOS2019/PReMVOS/code/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = \"../data/UTUBE/JPEGImages/\"\n",
    "first_frame_anns = \"../data/UTUBE/Annotations/\"\n",
    "# first_frame_anns = \"/home/hthieu/UTUBEVOS2019/PReMVOS/data/Annotations_debug/\"\n",
    "input_proposals = \"../output/intermediate/ReID_proposals/\"\n",
    "input_optical_flow = \"../output/intermediate/flow/\"\n",
    "output_images = \"../output/final/\"\n",
    "\n",
    "curr_run_num = 0\n",
    "total_to_run = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating testnet...\n",
      "using bbox guidance\n",
      "INFO:tensorflow:Summary name valdata/ground truth segmentation labels is illegal; using valdata/ground_truth_segmentation_labels instead.\n",
      "INFO:tensorflow:Summary name valdata/bbox guidance is illegal; using valdata/bbox_guidance instead.\n",
      "network:\n",
      "testnet output : Using SEGMENTATION_LABELS_ORIGINAL_SIZE for calculating IoU\n",
      "INFO:tensorflow:Summary name predicted labels is illegal; using predicted_labels instead.\n",
      "loading model from ../weights/PReMVOS_weights/refinement_net/specific_weights/refinement_specific_weights\n",
      "INFO:tensorflow:Restoring parameters from ../weights/PReMVOS_weights/refinement_net/specific_weights/refinement_specific_weights\n",
      "../output/logs/ReID_net ReID_general_weights .log\n",
      "number of parameters: 124,824,040\n",
      "loading model from ../weights/PReMVOS_weights/ReID_net/general_weights/ReID_general_weights\n",
      "INFO:tensorflow:Restoring parameters from ../weights/PReMVOS_weights/ReID_net/general_weights/ReID_general_weights\n"
     ]
    }
   ],
   "source": [
    "from MergeTrack.merge_functions import read_ann,read_props,calculate_scores,calculate_selected_props,\\\n",
    "  remove_mask_overlap,warp_proposals,update_templates,save_pngs,viz_scores,eval_video,calculate_gt_scores,\\\n",
    "  probabilitic_combination\n",
    "\n",
    "from MergeTrack.refinement_net_functions import refinement_net_init, do_refinement\n",
    "refinement_net = refinement_net_init()\n",
    "\n",
    "from MergeTrack.ReID_net_functions import ReID_net_init, add_ReID\n",
    "ReID_net = ReID_net_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_video(video_fn, vis_frames = []):\n",
    "    print(\"Starting\", video_fn)\n",
    "    final_solution = []\n",
    "    templates = []\n",
    "    next_props = []\n",
    "    image_fn_list = sorted(glob.glob(video_fn + \"*\"))\n",
    "    \n",
    "    for image_id, image_fn in enumerate(image_fn_list):\n",
    "        vis = any([x in image_fn for x in vis_frames])\n",
    "        ann_fn = image_fn.replace(input_images, first_frame_anns).replace('.jpg', '.png')\n",
    "        if glob.glob(ann_fn):\n",
    "            # ban chat: doc file mask, duoi dang 1 file json gom toa do bbox, segmentation, embeding vector  cua re ID\n",
    "            new_templates = read_ann(ann_fn)\n",
    "            new_templates = add_ReID(new_templates, image_fn, ReID_net)\n",
    "            templates = templates + copy(new_templates) # luu vao templates\n",
    "            next_props = next_props + copy(new_templates) # luu vao next_props\n",
    "\n",
    "        if templates:\n",
    "            # doc file .json, lay danh sach cac proposal (khoang tu 8 - 12 proposal/file)\n",
    "            prop_fn = image_fn.replace(input_images, input_proposals).replace('.jpg', '.json')\n",
    "            proposals = next_props + read_props(prop_fn)\n",
    "            \n",
    "            \n",
    "            print(prop_fn)\n",
    "            print(len(proposals), len(templates))\n",
    "            ipdb.set_trace()\n",
    "            if vis:\n",
    "                print(\"PROPOSALS CANDIDATE\")\n",
    "                vis_json(proposals, json_name2jpg_name(prop_fn))\n",
    "            # tinh 5 scores, nhan voi trong so tuong ung\n",
    "            all_scores = calculate_scores(proposals, templates)\n",
    "            weighted_scores = np.dot(normalised_weights, all_scores.transpose((1, 0, 2)), )\n",
    "            object_scores = np.dot(np.array([1, 1]), all_scores[:2, :, :].transpose((1, 0, 2)), )\n",
    "            selected_props = calculate_selected_props(proposals, weighted_scores, templates, score_thesh, object_scores)\n",
    "            \n",
    "            if vis:\n",
    "                print(\"SELECTED PROPOSALS\")\n",
    "                vis_json(selected_props, json_name2jpg_name(prop_fn))\n",
    "            \n",
    "            selected_props = remove_mask_overlap(selected_props)\n",
    "            \n",
    "            if vis:\n",
    "                print(\"REMOVE OVERLAP\")\n",
    "                vis_json(selected_props, json_name2jpg_name(prop_fn))\n",
    "\n",
    "            optflow_fn = image_fn.replace(input_images, input_optical_flow).replace('.jpg', '.flo')\n",
    "            \n",
    "            if glob.glob(optflow_fn):\n",
    "                next_image_fn = image_fn_list[image_id + 1]\n",
    "                next_props = warp_proposals(selected_props, optflow_fn)\n",
    "\n",
    "                next_props = do_refinement(next_props, next_image_fn, refinement_net)\n",
    "                next_props = add_ReID(next_props, next_image_fn, ReID_net)\n",
    "                templates = update_templates(templates, next_props)\n",
    "            else:\n",
    "                print(\"END\")\n",
    "            final_solution.append((image_fn, selected_props))\n",
    "            output_image_fn = image_fn.replace(input_images, output_images).replace('.jpg', '.png')\n",
    "            print(output_image_fn)\n",
    "            save_pngs(selected_props, output_image_fn)\n",
    "        else:\n",
    "            output_image_fn = image_fn.replace(input_images, output_images).replace('.jpg', '.png')\n",
    "            print(output_image_fn)\n",
    "            img = imread(image_fn)\n",
    "            temp_props = [dict()]\n",
    "            temp_props[0]['mask'] = np.zeros_like(img[:, :, 1]).astype(np.uint8)\n",
    "            save_pngs(temp_props, output_image_fn, empty=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_thesh = 1e-10\n",
    "\n",
    "weights = np.array([0.25920137, 0.22541801, 0.0775609,  0.12509281, 0.3127269 ])\n",
    "\n",
    "normalised_weights = weights / np.sum(weights)\n",
    "\n",
    "final_scores = []\n",
    "# video_list = sorted(glob.glob(input_proposals+\"0c7ba00455/\")) # 2 may bay\n",
    "# video_list = sorted(glob.glob(input_proposals+\"fef14bb2f2/\")) # 2 nguoi\n",
    "# video_list = sorted(glob.glob(input_proposals+\"fd237cf4fb/\")) # 1 con hai cau\n",
    "video_list = sorted(glob.glob(input_proposals+\"f9f9aa431c/\"))\n",
    "vis_frames = ['00045', '00050']\n",
    "\n",
    "#fef14bb2f\n",
    "video_list = [v.replace(input_proposals,input_images) for v in video_list]\n",
    "num_per = int(np.ceil(len(video_list)/total_to_run))\n",
    "print(curr_run_num,num_per,curr_run_num*num_per,(curr_run_num+1)*num_per)\n",
    "for video_fn in video_list[curr_run_num*num_per : (curr_run_num+1)*num_per]:\n",
    "  do_video(video_fn, vis_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "a = read_props('../output/intermediate/ReID_proposals/f9f9aa431c/00000.json')\n",
    "img = Image.open('../data/UTUBE/JPEGImages/f9f9aa431c/00000.jpg')\n",
    "drw = ImageDraw.Draw(img)\n",
    "x,y,w,h = a[1]['bbox']\n",
    "drw.rectangle([x,y,x+w,y+h], outline = 'black')\n",
    "\n",
    "def cal_center(proposals):\n",
    "    res = []\n",
    "    for prop in proposals:\n",
    "        x_c, y_c = prop['bbox'][0] + prop['bbox'][2] * 0.5, prop['bbox'][1] + prop['bbox'][3] \n",
    "        res.append((x_c, y_c))\n",
    "    return res\n",
    "res = cal_center(a) \n",
    "drw.point(res[1], fill = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408.40000915527344, 571.0000076293945)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(327.6000061035156, 480.6000061035156, 161.60000610351562, 90.4000015258789)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(res[1])\n",
    "x,y,w,h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
